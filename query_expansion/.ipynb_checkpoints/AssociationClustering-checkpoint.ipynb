{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "804250f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "import heapq\n",
    "\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import PorterStemmer\n",
    "# import pysolr\n",
    "import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "508e2e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_doc(doc_text, stop_words):\n",
    "    # doc_text = doc_text.replace('\\n', ' ')\n",
    "    # doc_text = \" \".join(re.findall('[a-zA-Z]+', doc_text))\n",
    "    # tokens = doc_text.split(' ')\n",
    "    tokens = []\n",
    "    text = doc_text\n",
    "    text = re.sub(r'[\\n]', ' ', text)\n",
    "    text = re.sub(r'[,-]', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub('[0-9]', '', text)\n",
    "    text = text.lower()\n",
    "    tkns = text.split(' ')\n",
    "    tokens = [token for token in tkns if token not in stop_words and token != '' and not token.isnumeric()]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c59f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_association(id_token_map, vocab, query):\n",
    "    association_list = []\n",
    "    for i, voc in enumerate(vocab):\n",
    "        for word in query.split(' '):\n",
    "            c1, c2, c3 = 0, 0, 0\n",
    "            for doc_id, tokens_this_doc in id_token_map.items():\n",
    "                count0 = tokens_this_doc.count(voc)\n",
    "                count1 = tokens_this_doc.count(word)\n",
    "                c1 += count0 * count1\n",
    "                c2 += count0 * count0\n",
    "                c3 += count1 * count1\n",
    "            c1 /= (c1 + c2 + c3)\n",
    "            if c1 != 0:\n",
    "                association_list.append((voc, word, c1))\n",
    "\n",
    "    return association_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87089341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def association_main(query, solr_results):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    #query = 'olympic medal'\n",
    "    # solr = pysolr.Solr('http://localhost:8983/solr/nutch/', always_commit=True, timeout=10)\n",
    "    # results = get_results_from_solr(query, solr)\n",
    "    tokens = []\n",
    "    token_counts = {}\n",
    "    tokens_map = {}\n",
    "    # tokens_map = collections.OrderedDict()\n",
    "    document_ids = []\n",
    "\n",
    "    for result in solr_results:\n",
    "        tokens_this_document = tokenize_doc(result['content'], stop_words)\n",
    "        tokens_map[result['digest']] = tokens_this_document\n",
    "        tokens.append(tokens_this_document)\n",
    "\n",
    "    vocab = set([token for tokens_this_doc in tokens for token in tokens_this_doc])\n",
    "    association_list = build_association(tokens_map, vocab, query)\n",
    "    association_list.sort(key = lambda x: x[2],reverse=True)\n",
    "    #print(association_list)\n",
    "    i=1;\n",
    "    while(i<5):\n",
    "        query += ' '+str(association_list[i][0])\n",
    "        i +=1\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d17198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('solr_data_500.json', 'r', encoding=\"utf8\") as f:\n",
    "    # Load JSON data as a list of dictionaries\n",
    "    data = json.load(f)\n",
    "\n",
    "doc_list = data[\"response\"][\"docs\"]\n",
    "documents = []\n",
    "for doc in doc_list:\n",
    "    if \"content\" in doc:\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc3c2ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"social\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2bd416b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "social media companies twitter facebook\n"
     ]
    }
   ],
   "source": [
    "queryRes = association_main(query, documents)\n",
    "print(queryRes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a5c3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0383ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
